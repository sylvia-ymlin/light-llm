#!/usr/bin/env python3
"""
è®­ç»ƒä¸€ä¸ªæ›´å¥½çš„è¯­è¨€æ¨¡å‹ï¼Œç”¨äºç”Ÿæˆè¿è´¯æ–‡æœ¬
"""

from llm_scratch.training.sft import train_sft

def create_better_training_data():
    """åˆ›å»ºæ›´å¥½çš„è®­ç»ƒæ•°æ®"""
    
    # æ›´å¤šæ ·åŒ–çš„è‹±æ–‡å¥å­
    sentences = [
        "Hello world, this is a test of our language model.",
        "The quick brown fox jumps over the lazy dog.",
        "Machine learning is a subset of artificial intelligence.",
        "Python is a popular programming language for data science.",
        "Natural language processing helps computers understand text.",
        "Deep learning models can generate human-like text.",
        "Transformers revolutionized the field of NLP.",
        "Attention mechanisms allow models to focus on relevant parts.",
        "Large language models are trained on massive datasets.",
        "Fine-tuning adapts pre-trained models to specific tasks.",
        "The weather is nice today, perfect for a walk.",
        "I enjoy reading books about science and technology.",
        "Cooking is both an art and a science.",
        "Music has the power to evoke strong emotions.",
        "Travel broadens the mind and enriches the soul.",
        "Education is the key to personal growth.",
        "Friendship is one of life's greatest treasures.",
        "Exercise is important for maintaining good health.",
        "Innovation drives progress in society.",
        "Creativity allows us to solve problems in new ways.",
    ]
    
    # åˆ›å»ºæ›´å¤šçš„è®­ç»ƒå¯¹
    training_pairs = []
    
    # 1. å¥å­è¡¥å…¨ä»»åŠ¡
    for sentence in sentences:
        words = sentence.split()
        for i in range(2, len(words)):
            prompt = " ".join(words[:i])
            response = " ".join(words[i:])
            training_pairs.append((prompt, response))
    
    # 2. é—®ç­”å¯¹
    qa_pairs = [
        ("What is machine learning?", "Machine learning is a method of data analysis that automates analytical model building."),
        ("How does Python help in programming?", "Python provides simple syntax and powerful libraries for various applications."),
        ("What are transformers in AI?", "Transformers are neural network architectures that use attention mechanisms."),
        ("Why is exercise important?", "Exercise helps maintain physical health and mental well-being."),
        ("What makes a good friend?", "A good friend is loyal, supportive, and trustworthy."),
    ]
    
    training_pairs.extend(qa_pairs)
    
    # 3. é‡å¤æ•°æ®ä»¥å¢åŠ è®­ç»ƒé‡
    training_pairs = training_pairs * 10  # æ‰©å±•åˆ°æ›´å¤šæ ·æœ¬
    
    print(f"Created {len(training_pairs)} training pairs")
    return training_pairs

def train_better_model():
    """è®­ç»ƒæ›´å¥½çš„æ¨¡å‹"""
    
    print("ğŸš€ Training Better Language Model")
    print("=" * 50)
    
    # åˆ›å»ºè®­ç»ƒæ•°æ®
    training_data = create_better_training_data()
    
    # è®­ç»ƒæ›´é•¿æ—¶é—´ï¼Œæ›´å¤§æ¨¡å‹
    train_sft(
        items=training_data,
        out_dir="runs/better_model",
        steps=200,  # æ›´å¤šè®­ç»ƒæ­¥éª¤
        batch_size=8,
        block_size=256,
        n_layer=6,  # æ›´æ·±çš„æ¨¡å‹
        n_head=6,
        n_embd=192,  # æ›´å¤§çš„åµŒå…¥ç»´åº¦
        lr=1e-4,  # è¾ƒå°çš„å­¦ä¹ ç‡
        device='cpu'  # ä½¿ç”¨CPUç¡®ä¿ç¨³å®š
    )
    
    print("âœ… Better model training completed!")
    return "runs/better_model/model_last.pt"

def test_better_model(model_path):
    """æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹"""
    import torch
    from llm_scratch.model.base import GPTModern
    from llm_scratch.data.tokenizers import ByteTokenizer
    
    print("\nğŸ§ª Testing Better Model")
    print("=" * 30)
    
    # åŠ è½½æ¨¡å‹
    ckpt = torch.load(model_path, map_location='cpu')
    config = ckpt['config']
    
    model = GPTModern(
        vocab_size=config['vocab_size'],
        block_size=config['block_size'],
        n_layer=config['n_layer'],
        n_head=config['n_head'],
        n_embd=config['n_embd']
    )
    model.load_state_dict(ckpt['model'])
    model.eval()
    
    tokenizer = ByteTokenizer()
    
    # æµ‹è¯•å¤šä¸ªprompt
    test_prompts = [
        "Hello world, this is",
        "Machine learning is",
        "The weather is",
        "Python is a",
        "I enjoy"
    ]
    
    for prompt in test_prompts:
        input_ids = tokenizer.encode(prompt).unsqueeze(0)
        
        with torch.no_grad():
            output = model.generate(
                input_ids, 
                max_new_tokens=20, 
                temperature=0.7, 
                top_k=20
            )
            
        generated_text = tokenizer.decode(output[0].tolist())
        print(f"Prompt: '{prompt}'")
        print(f"Generated: '{generated_text}'")
        print()

if __name__ == "__main__":
    # è®­ç»ƒæ›´å¥½çš„æ¨¡å‹
    model_path = train_better_model()
    
    # æµ‹è¯•æ¨¡å‹
    test_better_model(model_path)